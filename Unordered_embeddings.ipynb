{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = [f for f in os.listdir('data/htm/') if '.htm' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple_TOU.htm', 'Termly-Website-Terms-and-Conditions-Template.htm']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('data/htm/', flist[0])) as f:\n",
    "    apple_soup = BeautifulSoup(f)\n",
    "\n",
    "with open(os.path.join('data/htm/', flist[1])) as f:\n",
    "    default_soup = BeautifulSoup(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_clean(soup):\n",
    "    paras = soup.find('div', {'class':'WordSection1'}).find_all('p', {'class':'MsoNormal'})\n",
    "    out_paras = [p.text.replace('\\xa0', ' ').replace('\\n', ' ') for p in paras]\n",
    "    return [p for p in out_paras if p != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_paras = find_and_clean(default_soup)\n",
    "apple_paras = find_and_clean(apple_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement similarities\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_flist = os.listdir(\"data/OPP/OPP-115/sanitized_policies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "def find_and_clean_OPP(f, fdir = \"data/OPP/OPP-115/sanitized_policies\"):\n",
    "    with open(os.path.join(fdir, f)) as j:\n",
    "        soup = BeautifulSoup(j)\n",
    "    paras = str(soup).split('<br/>')\n",
    "    paras = [BeautifulSoup(p).text.replace(\"|||\", '') for p in paras]\n",
    "    paras = [p for p in paras if p != \" \"]\n",
    "    paras = [word_tokenize(p) for p in paras]#[p.split(' ') for p in paras]\n",
    "    exclude = set(string.punctuation)\n",
    "    stop = set(stopwords.words('english'))\n",
    "    ans = []\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    for clause in paras:\n",
    "        s = []\n",
    "        for word in clause:\n",
    "            if word != \"\" and word not in stop:\n",
    "                w = word.translate(translator).strip()\n",
    "                if w!= '':\n",
    "                    s.append(w.lower())\n",
    "        ans.append(s)\n",
    "    \n",
    "            \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= []\n",
    "for i in opp_flist:\n",
    "    df.extend(find_and_clean_OPP(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = [a for a in df if len(a) >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fast_embed = FastText(size = 300, window = 3, min_count = 1, sentences= df2, iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\shared\\work 2020\\workenv\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('viprivacy', 0.9854973554611206),\n",
       " ('privacyadmin', 0.9761562943458557),\n",
       " ('privacypolicy', 0.9581217169761658),\n",
       " ('bankingprivacy', 0.952069103717804),\n",
       " ('zipscenecomprivacy', 0.9443008899688721),\n",
       " ('privacycoordinator', 0.9410880208015442),\n",
       " ('wwwaddthiscomprivacy', 0.934051513671875),\n",
       " ('profileprivacy', 0.9302988052368164),\n",
       " ('wwwqriocitycomusenlegalprivacy', 0.9260797500610352),\n",
       " ('privacystatement', 0.9226903915405273)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_embed.most_similar(['privacy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct sentence matrix\n",
    "### (x, y) matrix x = word_embeddings_length, y = number of words; output (x dimension sentence vector)\n",
    "\n",
    "def construct_mat(sent, model):\n",
    "    return np.array([model[w] for w in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word to sentence embeddings \n",
    "### (x, y) matrix x = word_embeddings_length, y = number of words; output (x dimension sentence vector)\n",
    "### According to https://arxiv.org/pdf/1805.09843.pdf; max pooling performs well in sentence comparisons\n",
    "def SWEM_max(mat):\n",
    "    return mat.max(axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## similarity\n",
    "## Given query vector (1, n) and response matrix (m, n), get most similar x vectors, lookup where they are\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "def sim_query(query, response, query_text, response_text, top_n =5):\n",
    "    total = np.vstack((query, response))\n",
    "    print(total.shape)\n",
    "    cos_sim = cosine_similarity(total)[0, :]\n",
    "    print(cos_sim[:10])\n",
    "    top_ind = cos_sim.T.argsort()[-(top_n+1):-1][::-1]\n",
    "    print(top_ind)\n",
    "    ans = []\n",
    "    for j in top_ind.tolist():\n",
    "        ans.append((cos_sim[j], response_text[j-1]))\n",
    "    \n",
    "    return (query_text, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_mat(corpus, model):\n",
    "    total_mat = np.empty((len(corpus), model.vector_size))\n",
    "    for ind, sent in enumerate(corpus):\n",
    "        sent_mat = construct_mat(sent, model)\n",
    "        try:\n",
    "            sent_vec = SWEM_max(sent_mat)\n",
    "        except:\n",
    "            print(ind)\n",
    "            print(sent_mat)\n",
    "        total_mat[ind, :] = sent_vec\n",
    "    return total_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\shared\\work 2020\\workenv\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "total_mat = corpus_mat(df2, fast_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = total_mat[:200, :]\n",
    "a = total_mat[200:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5550, 300)\n",
      "[1.         0.35501206 0.35765111 0.34865871 0.65293289 0.69575604\n",
      " 0.37571999 0.74880933 0.88568868 0.90868697]\n",
      "[1564 5220 1683 5444 2672]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['in',\n",
       "  'course',\n",
       "  'serving',\n",
       "  'advertisements',\n",
       "  'site',\n",
       "  'thirdparty',\n",
       "  'advertiser',\n",
       "  'may',\n",
       "  'place',\n",
       "  'recognize',\n",
       "  'unique',\n",
       "  'cookie',\n",
       "  'browser'],\n",
       " [(0.9740945466071076,\n",
       "   ['in',\n",
       "    'course',\n",
       "    'serving',\n",
       "    'advertisements',\n",
       "    'site',\n",
       "    'thirdparty',\n",
       "    'advertiser',\n",
       "    'may',\n",
       "    'place',\n",
       "    'recognize',\n",
       "    'unique',\n",
       "    'cookie',\n",
       "    'browser',\n",
       "    'if',\n",
       "    'would',\n",
       "    'like',\n",
       "    'information',\n",
       "    'practice',\n",
       "    'know',\n",
       "    'choices',\n",
       "    'information',\n",
       "    'used',\n",
       "    'company',\n",
       "    'please',\n",
       "    'click']),\n",
       "  (0.9731735683035212,\n",
       "   ['pbs',\n",
       "    'uses',\n",
       "    'content',\n",
       "    'cookies',\n",
       "    'deliver',\n",
       "    'relevant',\n",
       "    'local',\n",
       "    'resources',\n",
       "    'remember',\n",
       "    'browser',\n",
       "    'preferences',\n",
       "    'improve',\n",
       "    'visitors',\n",
       "    'experiences',\n",
       "    'site',\n",
       "    'pbs',\n",
       "    'sell',\n",
       "    'information',\n",
       "    'collected',\n",
       "    'cookies',\n",
       "    'use',\n",
       "    'information',\n",
       "    'commercerelated',\n",
       "    'purposes',\n",
       "    'in',\n",
       "    'addition',\n",
       "    'pbs',\n",
       "    'filter',\n",
       "    'content',\n",
       "    'based',\n",
       "    'preferences',\n",
       "    'without',\n",
       "    'permission']),\n",
       "  (0.9595453112509247,\n",
       "   ['some',\n",
       "    'services',\n",
       "    'advertisements',\n",
       "    'included',\n",
       "    'sidearm',\n",
       "    'services',\n",
       "    'including',\n",
       "    'web',\n",
       "    'sites',\n",
       "    'within',\n",
       "    'mobile',\n",
       "    'apps',\n",
       "    'delivered',\n",
       "    'served',\n",
       "    'thirdparty',\n",
       "    'companies',\n",
       "    'these',\n",
       "    'companies',\n",
       "    'may',\n",
       "    'place',\n",
       "    'recognize',\n",
       "    'cookies',\n",
       "    'web',\n",
       "    'beacons',\n",
       "    'technology',\n",
       "    'track',\n",
       "    'certain',\n",
       "    'nonpersonal',\n",
       "    'information',\n",
       "    'website',\n",
       "    'users',\n",
       "    'for',\n",
       "    'example',\n",
       "    'course',\n",
       "    'serving',\n",
       "    'certain',\n",
       "    'advertisements',\n",
       "    'advertiser',\n",
       "    'may',\n",
       "    'place',\n",
       "    'recognize',\n",
       "    'unique',\n",
       "    'cookie',\n",
       "    'browser',\n",
       "    'order',\n",
       "    'collect',\n",
       "    'certain',\n",
       "    'information',\n",
       "    'use',\n",
       "    'sidearm',\n",
       "    'services',\n",
       "    'in',\n",
       "    'many',\n",
       "    'cases',\n",
       "    'information',\n",
       "    'could',\n",
       "    'used',\n",
       "    'show',\n",
       "    'ads',\n",
       "    'websites',\n",
       "    'based',\n",
       "    'interests']),\n",
       "  (0.9572459809143902,\n",
       "   ['what',\n",
       "    'clear',\n",
       "    'gifs',\n",
       "    'clear',\n",
       "    'gifs',\n",
       "    'tiny',\n",
       "    'graphics',\n",
       "    'unique',\n",
       "    'identifier',\n",
       "    'similar',\n",
       "    'function',\n",
       "    'cookies',\n",
       "    'used',\n",
       "    'track',\n",
       "    'online',\n",
       "    'movements',\n",
       "    'web',\n",
       "    'users',\n",
       "    'in',\n",
       "    'contrast',\n",
       "    'cookies',\n",
       "    'stored',\n",
       "    'users',\n",
       "    'computer',\n",
       "    'hard',\n",
       "    'drive',\n",
       "    'clear',\n",
       "    'gifs',\n",
       "    'embedded',\n",
       "    'invisibly',\n",
       "    'web',\n",
       "    'pages',\n",
       "    'size',\n",
       "    'fullstop',\n",
       "    'period',\n",
       "    'end',\n",
       "    'sentence']),\n",
       "  (0.9517039182786001,\n",
       "   ['these',\n",
       "    'companies',\n",
       "    'may',\n",
       "    'place',\n",
       "    'recognize',\n",
       "    'cookies',\n",
       "    'web',\n",
       "    'beacons',\n",
       "    'technology',\n",
       "    'track',\n",
       "    'certain',\n",
       "    'nonpersonal',\n",
       "    'information',\n",
       "    'website',\n",
       "    'users',\n",
       "    'for',\n",
       "    'example',\n",
       "    'course',\n",
       "    'serving',\n",
       "    'certain',\n",
       "    'advertisements',\n",
       "    'advertiser',\n",
       "    'may',\n",
       "    'place',\n",
       "    'recognize',\n",
       "    'unique',\n",
       "    'cookie',\n",
       "    'browser',\n",
       "    'order',\n",
       "    'collect',\n",
       "    'certain',\n",
       "    'information',\n",
       "    'use',\n",
       "    'nyt',\n",
       "    'services',\n",
       "    'for',\n",
       "    'another',\n",
       "    'example',\n",
       "    'advertiser',\n",
       "    'ad',\n",
       "    'server',\n",
       "    'may',\n",
       "    'also',\n",
       "    'able',\n",
       "    'collect',\n",
       "    'device',\n",
       "    's',\n",
       "    'unique',\n",
       "    'identifier',\n",
       "    'course',\n",
       "    'serving',\n",
       "    'ad',\n",
       "    'in',\n",
       "    'many',\n",
       "    'cases',\n",
       "    'information',\n",
       "    'could',\n",
       "    'used',\n",
       "    'show',\n",
       "    'ads',\n",
       "    'websites',\n",
       "    'based',\n",
       "    'interests'])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_query(q[50], a, df2[50], df2[200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
